#!/usr/bin/env python3
"""
Demo script to test fall detection on existing video
This analyzes the bison.mp4 file to demonstrate the system
"""

import cv2
import base64
from openai import OpenAI
import os
import dotenv
from rich.console import Console
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich import print as rprint

dotenv.load_dotenv()
console = Console()

def save_demo_frames(video_path, base64_frames):
    """Save demo frames to temp directory in various formats"""
    try:
        from datetime import datetime
        import imageio
        
        save_format = os.environ.get("SAVE_FORMAT", "images").lower()
        
        # Create temp directory
        temp_dir = "temp"
        demo_dir = os.path.join(temp_dir, f"demo_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
        os.makedirs(demo_dir, exist_ok=True)
        
        # Decode all frames first
        frame_arrays = []
        saved_files = []
        
        for i, base64_frame in enumerate(base64_frames):
            try:
                # Decode base64 to image
                import base64
                import numpy as np
                img_data = base64.b64decode(base64_frame)
                nparr = np.frombuffer(img_data, np.uint8)
                frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
                frame_arrays.append(frame)
                
                # Save individual images if needed
                if save_format in ["images", "all"]:
                    filename = f"frame_{i+1:03d}.jpg"
                    filepath = os.path.join(demo_dir, filename)
                    cv2.imwrite(filepath, frame)
                    saved_files.append(filepath)
                    
            except Exception as e:
                console.print(f"[yellow]‚ö† Kh√¥ng th·ªÉ x·ª≠ l√Ω frame {i+1}: {e}[/yellow]")
        
        # Save as GIF if requested
        if save_format in ["gif", "all"] and len(frame_arrays) > 1:
            gif_path = os.path.join(demo_dir, "demo_analysis.gif")
            # Convert BGR to RGB for imageio
            rgb_frames = [cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) for frame in frame_arrays]
            imageio.mimsave(gif_path, rgb_frames, duration=0.1, loop=0)  # 5x faster (10 FPS)
            saved_files.append(gif_path)
            console.print(f"[green]üéûÔ∏è ƒê√£ t·∫°o GIF: [cyan]{gif_path}[/cyan][/green]")
        
        # Save as MP4 video if requested
        if save_format in ["video", "all"] and len(frame_arrays) > 1:
            video_path_output = os.path.join(demo_dir, "demo_analysis.mp4")
            save_demo_video(frame_arrays, video_path_output, fps=10.0)  # 5x faster (10 FPS)
            saved_files.append(video_path_output)
            console.print(f"[green]üé¨ ƒê√£ t·∫°o video: [cyan]{video_path_output}[/cyan][/green]")
        
        # Save video info
        video_name = os.path.basename(video_path)
        info_file = os.path.join(demo_dir, "analysis_info.txt")
        with open(info_file, 'w', encoding='utf-8') as f:
            f.write(f"Demo Analysis Information\n")
            f.write(f"========================\n")
            f.write(f"Original video: {video_name}\n")
            f.write(f"Analysis time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Total frames analyzed: {len(frame_arrays)}\n")
            f.write(f"Save format: {save_format}\n")
            if save_format in ["gif", "all"]:
                f.write(f"GIF duration: {len(frame_arrays) * 0.1:.1f}s (10 FPS)\n")
            if save_format in ["video", "all"]:
                f.write(f"Video duration: {len(frame_arrays) / 10.0:.1f}s (10 FPS)\n")
            f.write(f"\nFiles saved:\n")
            for file_path in saved_files:
                f.write(f"- {os.path.basename(file_path)}\n")
        
        format_icons = {"images": "üñºÔ∏è", "gif": "üéûÔ∏è", "video": "üé¨", "all": "üì¶"}
        icon = format_icons.get(save_format, "üíæ")
        
        console.print(f"[green]{icon} ƒê√£ l∆∞u {len(saved_files)} file demo ({save_format}) t·∫°i: [cyan]{demo_dir}[/cyan][/green]")
        
    except Exception as e:
        console.print(f"[red]‚ùå L·ªói khi l∆∞u frames demo: {e}[/red]")

def save_demo_video(frames, output_path, fps=10.0):
    """Save demo frames as MP4 video"""
    try:
        if not frames:
            return
        
        height, width, layers = frames[0].shape
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        video_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        for frame in frames:
            video_writer.write(frame)
        
        video_writer.release()
        
    except Exception as e:
        console.print(f"[red]‚ùå Kh√¥ng th·ªÉ t·∫°o demo video: {e}[/red]")

def analyze_video_for_falls(video_path="bison.mp4"):
    """Analyze video file for potential falls"""
    
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
    save_frames = os.environ.get("SAVE_ANALYSIS_FRAMES", "false").lower() == "true"
    
    if not os.path.exists(video_path):
        console.print(f"[red]‚ùå Kh√¥ng t√¨m th·∫•y file video {video_path}[/red]")
        return
    
    console.print(f"[blue]üìπ ƒêang ph√¢n t√≠ch video:[/blue] [cyan]{video_path}[/cyan]")
    
    # Extract frames from video
    video = cv2.VideoCapture(video_path)
    base64_frames = []
    frame_count = 0
    
    while video.isOpened() and frame_count < 100:  # Limit frames for demo
        success, frame = video.read()
        if not success:
            break
        
        frame_count += 1
        
        # Take every 10th frame to reduce processing
        if frame_count % 10 == 0:
            _, buffer = cv2.imencode(".jpg", frame, [cv2.IMWRITE_JPEG_QUALITY, 80])
            base64_frame = base64.b64encode(buffer).decode("utf-8")
            base64_frames.append(base64_frame)
    
    video.release()
    console.print(f"[green]üìä ƒê√£ tr√≠ch xu·∫•t {len(base64_frames)} khung h√¨nh ƒë·ªÉ ph√¢n t√≠ch[/green]")
    
    if not base64_frames:
        console.print("[red]‚ùå Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c khung h√¨nh t·ª´ video[/red]")
        return
    
    # Save frames if enabled
    if save_frames:
        save_demo_frames(video_path, base64_frames)
    
    # Analyze frames with OpenAI
    try:
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console,
        ) as progress:
            task = progress.add_task("[cyan]ü§ñ ƒêang ph√¢n t√≠ch v·ªõi AI...", total=None)
        
        messages = [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": """B·∫°n l√† tr·ª£ l√Ω AI chuy√™n v·ªÅ ph√¢n t√≠ch ph√°t hi·ªán t√© ng√£. 
                        H√£y ph√¢n t√≠ch c√°c khung h√¨nh video n√†y v√† x√°c ƒë·ªãnh xem c√≥ x·∫£y ra t√© ng√£ c·ªßa con ng∆∞·ªùi hay kh√¥ng.
                        
                        T√¨m ki·∫øm c√°c d·∫•u hi·ªáu sau:
                        - Ng∆∞·ªùi b·∫•t ng·ªù thay ƒë·ªïi t·ª´ t∆∞ th·∫ø ƒë·ª©ng/ng·ªìi sang t∆∞ th·∫ø n·∫±m ngang
                        - Chuy·ªÉn ƒë·ªông nhanh xu·ªëng d∆∞·ªõi
                        - Ng∆∞·ªùi n·∫±m tr√™n s√†n trong t√¨nh tr·∫°ng kh√≥ khƒÉn
                        - ƒê·ªôt ng·ªôt ng√£ ho·∫∑c m·∫•t thƒÉng b·∫±ng
                        - T√¨nh hu·ªëng kh·∫©n c·∫•p c·∫ßn s·ª± ch√∫ √Ω ngay l·∫≠p t·ª©c
                        
                        C≈©ng cung c·∫•p m√¥ t·∫£ t·ªïng qu√°t v·ªÅ nh·ªØng g√¨ b·∫°n th·∫•y trong video.
                        
                        Tr·∫£ l·ªùi theo ƒë·ªãnh d·∫°ng n√†y:
                        T√åNH_TR·∫†NG_T√â_NG√É: [PH√ÅT_HI·ªÜN/KH√îNG_PH√ÅT_HI·ªÜN]
                        M√î_T·∫¢: [Nh·ªØng g√¨ b·∫°n th·∫•y trong video]
                        PH√ÇN_T√çCH: [Ph√¢n t√≠ch chi ti·∫øt v·ªÅ c√°c chuy·ªÉn ƒë·ªông ho·∫∑c ho·∫°t ƒë·ªông]"""
                    }
                ] + [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{frame}"
                        }
                    }
                    for frame in base64_frames[:8]  # Analyze first 8 frames
                ]
            }
        ]
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            max_tokens=400
        )
        
        analysis_result = response.choices[0].message.content.strip()
        
        # Display results in a beautiful panel
        result_panel = Panel(
            analysis_result,
            title="[bold green]üéØ K·∫æT QU·∫¢ PH√ÇN T√çCH[/bold green]",
            border_style="green",
            padding=(1, 2)
        )
        console.print(result_panel)
        
        # Check if fall was detected
        if "T√åNH_TR·∫†NG_T√â_NG√É: PH√ÅT_HI·ªÜN" in analysis_result:
            console.print("\n[red]üö® PH√ÅT HI·ªÜN T√â NG√É trong video![/red]")
        else:
            console.print("\n[green]‚úÖ Kh√¥ng ph√°t hi·ªán t√© ng√£ trong video[/green]")
            
    except Exception as e:
        console.print(f"[red]‚ùå L·ªói trong qu√° tr√¨nh ph√¢n t√≠ch: {e}[/red]")

def main():
    """Main demo function"""
    startup_panel = Panel(
        "[bold blue]üé¨ Demo Ph√¢n T√≠ch Video Ph√°t Hi·ªán T√© Ng√£[/bold blue]\n\n"
        "[yellow]Ch∆∞∆°ng tr√¨nh n√†y s·∫Ω ph√¢n t√≠ch video ƒë·ªÉ t√¨m ki·∫øm d·∫•u hi·ªáu t√© ng√£[/yellow]",
        title="[bold green]DEMO SYSTEM[/bold green]",
        border_style="blue",
        padding=(1, 2)
    )
    console.print(startup_panel)
    
    # Check if OpenAI API key is available
    if not os.environ.get("OPENAI_API_KEY"):
        console.print("[red]‚ùå Kh√¥ng t√¨m th·∫•y OPENAI_API_KEY trong bi·∫øn m√¥i tr∆∞·ªùng[/red]")
        console.print("[yellow]Vui l√≤ng thi·∫øt l·∫≠p file .env tr∆∞·ªõc[/yellow]")
        return
    
    # Check if video file exists
    video_files = ['src/media/fall-01-cam0.mp4', 'src/media/fall-01-cam1.mp4']
    video_to_analyze = None
    
    for video_file in video_files:
        if os.path.exists(video_file):
            video_to_analyze = video_file
            break
    
    if not video_to_analyze:
        console.print("[red]‚ùå Kh√¥ng t√¨m th·∫•y file video ƒë·ªÉ ph√¢n t√≠ch[/red]")
        console.print("[yellow]C√°c t√πy ch·ªçn c√≥ s·∫µn: bison.mp4, output.mp4[/yellow]")
        return
    
    # Run analysis
    analyze_video_for_falls(video_to_analyze)
    
    info_panel = Panel(
        "[blue]üí° Demo n√†y cho th·∫•y c√°ch AI ph√¢n t√≠ch n·ªôi dung video.[/blue]\n"
        "[green]H·ªá th·ªëng th·ªùi gian th·ª±c ho·∫°t ƒë·ªông t∆∞∆°ng t·ª± nh∆∞ng v·ªõi camera tr·ª±c ti·∫øp.[/green]",
        title="[bold cyan]TH√îNG TIN[/bold cyan]",
        border_style="cyan"
    )
    console.print(info_panel)

if __name__ == "__main__":
    main() 