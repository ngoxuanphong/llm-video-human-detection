# Hi·ªÉu v√† m√¥ t·∫£ d·ª± √°n chi ti·∫øt
_Exported on 6/30/2025 at 11:16:40 GMT+7 from Cursor (1.1.6)_

---

**User**

@main_ui.py @/src hi·ªÉu to√†n b·ªô project, m√¥ t·∫£ l·∫°i cho t√¥i t·ª´ng m√¥ ƒëun chi ti·∫øt v√† v·∫Ω s∆° ƒë·ªì kh·ªëi 

---

**Cursor**

T√¥i s·∫Ω ƒë·ªçc t·∫•t c·∫£ c√°c file trong th∆∞ m·ª•c src ƒë·ªÉ hi·ªÉu to√†n b·ªô project v√† m√¥ t·∫£ chi ti·∫øt t·ª´ng m√¥ ƒëun.

D·ª±a tr√™n vi·ªác ph√¢n t√≠ch to√†n b·ªô source code, t√¥i s·∫Ω m√¥ t·∫£ chi ti·∫øt t·ª´ng m√¥ ƒëun v√† v·∫Ω s∆° ƒë·ªì kh·ªëi c·ªßa h·ªá th·ªëng ph√°t hi·ªán t√© ng√£ n√†y.

## **üìã M√î T·∫¢ T·ªîNG QUAN PROJECT**

ƒê√¢y l√† **H·ªá Th·ªëng Ph√°t Hi·ªán T√© Ng√£ B·ªánh Vi·ªán** s·ª≠ d·ª•ng AI v·ªõi c√°c t√≠nh nƒÉng:
- **Ph√°t hi·ªán t√© ng√£ th·ªùi gian th·ª±c** t·ª´ camera
- **Ph√¢n t√≠ch video upload** ƒë·ªÉ t√¨m t√© ng√£  
- **2 ph∆∞∆°ng th·ª©c AI**: VLM SmolVLM v√† VideoLLaMA3 + OpenAI hybrid
- **C·∫£nh b√°o ƒëa k√™nh**: √¢m thanh, Telegram, l∆∞u b·∫±ng ch·ª©ng GIF
- **Giao di·ªán web** th√¢n thi·ªán v·ªõi Gradio

---

## **üîß CHI TI·∫æT T·ª™NG M√î ƒêUN**

### **1. üéØ `main_ui.py` - Giao Di·ªán Web Ch√≠nh (1289 lines)**
**Ch·ª©c nƒÉng**: Giao di·ªán web ch√≠nh s·ª≠ d·ª•ng Gradio
- **Class `FallDetectionWebUI`**: Core system controller
- **Camera Management**: Kh·ªüi t·∫°o, ƒëi·ªÅu khi·ªÉn camera real-time
- **Frame Processing**: Buffer frames, ph√¢n t√≠ch theo chu k·ª≥
- **Detection Methods**: Chuy·ªÉn ƒë·ªïi gi·ªØa OpenAI v√† VideoLLaMA3
- **UI Components**: 6 tabs - Camera, Logs, Alerts, Upload, Evidence, Config
- **Auto-refresh**: Dual timers (0.1s camera, 2s status)
- **Evidence Management**: L∆∞u v√† hi·ªÉn th·ªã GIF b·∫±ng ch·ª©ng

### **2. ‚öôÔ∏è `src/__init__.py` - C·∫•u H√¨nh H·ªá Th·ªëng (52 lines)**
**Ch·ª©c nƒÉng**: C·∫•u h√¨nh to√†n b·ªô h·ªá th·ªëng v√† kh·ªüi t·∫°o services
```python
# C√°c bi·∫øn c·∫•u h√¨nh ch√≠nh:
OPENAI_CLIENT: OpenAI client
TELEGRAM_BOT: Bot instance (n·∫øu enabled)
SAVE_ANALYSIS_FRAMES: C√≥ l∆∞u frames kh√¥ng
SAVE_FORMAT: images/gif/video/all
MAX_FRAMES: S·ªë frames t·ªëi ƒëa g·ª≠i AI (default: 5)
```

### **3. üõ†Ô∏è `src/utils.py` - H√†m Ti·ªán √çch (142 lines)**
**Ch·ª©c nƒÉng**: X·ª≠ l√Ω frames v√† t∆∞∆°ng t√°c v·ªõi AI
- **`prepare_messages()`**: T·∫°o prompts ti·∫øng Vi·ªát cho OpenAI
- **`frames_to_base64()`**: Chuy·ªÉn frames sang base64 ƒë·ªÉ g·ª≠i API
- **`save_analysis_frames_to_temp()`**: L∆∞u frames ph√¢n t√≠ch (GIF/video)
- **`save_demo_video()`**: T·∫°o MP4 t·ª´ frames

### **4. ü§ñ `src/videollama_detector.py` - VideoLLaMA3 Detector (269 lines)**
**Ch·ª©c nƒÉng**: M√¥ ƒëun ph√°t hi·ªán hybrid VideoLLaMA3 + OpenAI
- **Class `VideoLLamaFallDetector`**: 
  - Model: DAMO-NLP-SG/VideoLLaMA3-2B
  - **2-step analysis**: VideoLLaMA3 m√¥ t·∫£ ‚Üí OpenAI ph√¢n t√≠ch ti·∫øng Vi·ªát
- **`load_model()`/`unload_model()`**: Qu·∫£n l√Ω model memory
- **`get_video_description()`**: VideoLLaMA3 m√¥ t·∫£ video (English)
- **`translate_to_vietnamese_analysis()`**: OpenAI ph√¢n t√≠ch ti·∫øng Vi·ªát
- **`analyze_frames()`**: Pipeline ho√†n ch·ªânh 2 b∆∞·ªõc

### **5. üîä `src/audio_warning.py` - H·ªá Th·ªëng C·∫£nh B√°o √Çm Thanh (331 lines)**
**Ch·ª©c nƒÉng**: Text-to-Speech c·∫£nh b√°o √¢m thanh
- **Class `AudioWarningSystem`**:
  - **ƒêa n·ªÅn t·∫£ng**: Google TTS, espeak-ng, Windows SAPI, macOS say
  - **∆Øu ti√™n Google TTS** cho ti·∫øng Vi·ªát ch·∫•t l∆∞·ª£ng cao
  - **Contextual warnings**: T·∫°o n·ªôi dung c·∫£nh b√°o d·ª±a tr√™n ph√¢n t√≠ch
- **`_detect_tts_system()`**: T·ª± ƒë·ªông ph√°t hi·ªán TTS kh·∫£ d·ª•ng
- **`play_warning_async()`**: Ph√°t √¢m thanh kh√¥ng ƒë·ªìng b·ªô

### **6. üì± `src/alert_services.py` - D·ªãch V·ª• Th√¥ng B√°o (36 lines)**
**Ch·ª©c nƒÉng**: G·ª≠i th√¥ng b√°o Telegram
- **`send_telegram_alert()`**: Async function g·ª≠i tin nh·∫Øn + ·∫£nh b·∫±ng ch·ª©ng
- T·ª± ƒë·ªông skip n·∫øu Telegram disabled
- Format tin nh·∫Øn chu·∫©n v·ªõi timestamp, v·ªã tr√≠, chi ti·∫øt

### **7. üöÄ `src/setup.py` - Script Thi·∫øt L·∫≠p (113 lines)**
**Ch·ª©c nƒÉng**: H∆∞·ªõng d·∫´n setup ban ƒë·∫ßu
- **`install_dependencies()`**: C√†i requirements.txt
- **`create_env_file()`**: T·∫°o .env t·ª´ template
- **`check_camera()`**: Ki·ªÉm tra camera kh·∫£ d·ª•ng
- **`print_next_steps()`**: H∆∞·ªõng d·∫´n b∆∞·ªõc ti·∫øp theo

### **8. üß™ `src/test_system.py` - Script Ki·ªÉm Tra (130 lines)**
**Ch·ª©c nƒÉng**: Test t·∫•t c·∫£ components tr∆∞·ªõc khi ch·∫°y
- **`test_camera()`**: Test camera connection
- **`test_openai_connection()`**: Test OpenAI API
- **`test_telegram_connection()`**: Test Telegram bot
- **`main()`**: Ch·∫°y t·∫•t c·∫£ tests v√† b√°o c√°o k·∫øt qu·∫£

---

## **üèóÔ∏è S∆† ƒê·ªí KH·ªêI H·ªÜ TH·ªêNG**

```python
# C√°c bi·∫øn c·∫•u h√¨nh ch√≠nh:
OPENAI_CLIENT: OpenAI client
TELEGRAM_BOT: Bot instance (n·∫øu enabled)
SAVE_ANALYSIS_FRAMES: C√≥ l∆∞u frames kh√¥ng
SAVE_FORMAT: images/gif/video/all
MAX_FRAMES: S·ªë frames t·ªëi ƒëa g·ª≠i AI (default: 5)
```

## **üîÑ LU·ªíNG X·ª¨ L√ù CHI TI·∫æT**

### **1. üìπ Lu·ªìng Camera Real-time**
```
Camera ‚Üí Frame Buffer (10s) ‚Üí Analysis Trigger (5s) ‚Üí AI Detection ‚Üí Alert Pipeline
```

### **2. üìÅ Lu·ªìng Video Upload**  
```
Upload File ‚Üí Read All Frames ‚Üí Sample Frames ‚Üí AI Analysis ‚Üí Evidence Generation
```

### **3. ü§ñ Lu·ªìng AI Detection (2 ch·∫ø ƒë·ªô)**

**Mode 1: OpenAI Direct**
```
Frames ‚Üí Base64 ‚Üí VLM SmolVLM ‚Üí Vietnamese Result
```

**Mode 2: VideoLLaMA3 Hybrid**  
```
Frames ‚Üí Video File ‚Üí VideoLLaMA3 ‚Üí English Description ‚Üí OpenAI ‚Üí Vietnamese Result
```

### **4. üö® Lu·ªìng Alert Multi-channel**
```
Fall Detected ‚Üí [Audio TTS + Telegram Message + GIF Evidence + System Logs] (Parallel)
```

---

## **‚ö° T√çNH NƒÇNG N·ªîI B·∫¨T**

### **üéØ AI Detection Capabilities**
- **Dual AI Methods**: OpenAI fast vs VideoLLaMA3 accurate
- **Vietnamese Processing**: Intelligent prompt engineering 
- **False Positive Reduction**: Careful prompt design
- **Real-time Analysis**: 5-second intervals

### **üîä Multi-platform Audio**
- **Google TTS**: Best Vietnamese quality (online)
- **espeak-ng**: Cross-platform offline TTS
- **System TTS**: Windows SAPI, macOS say
- **Contextual Messages**: Smart warning generation

### **üì± Evidence & Alerts**
- **GIF Evidence**: 5x speed for quick review
- **Telegram Integration**: Instant notifications with photos
- **Comprehensive Logging**: Detailed system logs
- **Evidence Gallery**: Browse and review all detections

### **üåê Web Interface**
- **Real-time UI**: Auto-refresh components
- **Multi-tab Design**: Organized functionality
- **Progress Tracking**: Video upload progress
- **Model Management**: Load/unload VideoLLaMA3

---

## **üîß KI·∫æN TR√öC K·ª∏ THU·∫¨T**

### **üìä Technology Stack**
- **Frontend**: Gradio (Python web framework)
- **Computer Vision**: OpenCV, PIL
- **AI Models**: VLM SmolVLM, VideoLLaMA3-2B
- **Audio**: gTTS, pygame, system TTS
- **Messaging**: Telegram Bot API
- **Threading**: Async/threading for non-blocking operations

### **üíæ Data Flow**
- **Frame Buffer**: Rolling 10-second window
- **Evidence Storage**: Organized timestamp folders
- **Configuration**: Environment-based settings
- **Model Memory**: Dynamic VideoLLaMA3 loading

### **üöÄ Performance Optimizations**
- **Frame Sampling**: Reduce processing load
- **Parallel Processing**: Multiple simultaneous alerts
- **Memory Management**: Model loading/unloading
- **Async Operations**: Non-blocking audio and alerts

H·ªá th·ªëng n√†y ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ **production-ready** v·ªõi kh·∫£ nƒÉng m·ªü r·ªông cao, ƒë·∫∑c bi·ªát ph√π h·ª£p cho m√¥i tr∆∞·ªùng b·ªánh vi·ªán c·∫ßn gi√°m s√°t t√© ng√£ 24/7.

```plaintext
Camera ‚Üí Frame Buffer (10s) ‚Üí Analysis Trigger (5s) ‚Üí AI Detection ‚Üí Alert Pipeline
```

```plaintext
Camera ‚Üí Frame Buffer (10s) ‚Üí Analysis Trigger (5s) ‚Üí AI Detection ‚Üí Alert Pipeline
```

```plaintext
Upload File ‚Üí Read All Frames ‚Üí Sample Frames ‚Üí AI Analysis ‚Üí Evidence Generation
```

```plaintext
Frames ‚Üí Base64 ‚Üí VLM SmolVLM ‚Üí Vietnamese Result
```

```plaintext
Frames ‚Üí Video File ‚Üí VideoLLaMA3 ‚Üí English Description ‚Üí OpenAI ‚Üí Vietnamese Result
```

```plaintext
Fall Detected ‚Üí [Audio TTS + Telegram Message + GIF Evidence + System Logs] (Parallel)
```

---

**User**

chi ti·∫øt v·ªÅ c·∫•u tr√∫c file, 
h∆∞·ªõng d·∫´n ch·∫°y project,
c√°c y√™u c·∫ßu v·ªÅ th∆∞ vi·ªán, ph·∫ßn c·ª©ng...

---

**Cursor**

T√¥i s·∫Ω ƒë·ªçc th√™m c√°c file c·∫•u h√¨nh v√† h∆∞·ªõng d·∫´n ƒë·ªÉ cung c·∫•p th√¥ng tin chi ti·∫øt v·ªÅ c·∫•u tr√∫c, y√™u c·∫ßu v√† c√°ch ch·∫°y project.

# üìö CHI TI·∫æT TO√ÄN DI·ªÜN V·ªÄ PROJECT FALL DETECTION SYSTEM

## üóÇÔ∏è **C·∫§U TR√öC FILE CHI TI·∫æT**

```
llm-video-human-detection/
‚îú‚îÄ‚îÄ üéØ **ENTRY POINTS**
‚îÇ   ‚îú‚îÄ‚îÄ main.py                     # Console version - Terminal interface
‚îÇ   ‚îú‚îÄ‚îÄ main_ui.py                  # Web UI version - Gradio interface  
‚îÇ   ‚îú‚îÄ‚îÄ start_web_ui.py             # Quick start script v·ªõi pre-checks
‚îÇ   ‚îî‚îÄ‚îÄ demo.py                     # Demo analysis script
‚îÇ
‚îú‚îÄ‚îÄ üîß **CONFIGURATION FILES**
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt            # Python dependencies
‚îÇ   ‚îú‚îÄ‚îÄ env_template.txt           # Environment variables template
‚îÇ   ‚îú‚îÄ‚îÄ .env                       # Environment configuration (t·∫°o t·ª´ template)
‚îÇ   ‚îú‚îÄ‚îÄ Makefile                   # Utility commands
‚îÇ   ‚îî‚îÄ‚îÄ README.md                  # Main documentation
‚îÇ
‚îú‚îÄ‚îÄ üß† **SOURCE CODE MODULES**
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py            # System configuration & initialization
‚îÇ       ‚îú‚îÄ‚îÄ utils.py               # Frame processing & AI utilities  
‚îÇ       ‚îú‚îÄ‚îÄ videollama_detector.py # VideoLLaMA3 hybrid detector
‚îÇ       ‚îú‚îÄ‚îÄ audio_warning.py       # Text-to-speech alert system
‚îÇ       ‚îú‚îÄ‚îÄ alert_services.py      # Telegram notification service
‚îÇ       ‚îú‚îÄ‚îÄ setup.py               # System setup script
‚îÇ       ‚îî‚îÄ‚îÄ test_system.py         # Component testing script
‚îÇ
‚îú‚îÄ‚îÄ üé¨ **ALTERNATE IMPLEMENTATIONS**
‚îÇ   ‚îî‚îÄ‚îÄ vid_llama.py               # Standalone VideoLLaMA3 script
‚îÇ
‚îú‚îÄ‚îÄ üìÅ **DATA DIRECTORIES** (auto-created)
‚îÇ   ‚îú‚îÄ‚îÄ temp/                      # Temporary analysis files
‚îÇ   ‚îú‚îÄ‚îÄ evidence/                  # Evidence images/videos
‚îÇ   ‚îú‚îÄ‚îÄ evidence_gifs/             # GIF evidence with timestamps
‚îÇ   ‚îú‚îÄ‚îÄ analysis/                  # Analysis results by timestamp
‚îÇ   ‚îî‚îÄ‚îÄ media/                     # Sample videos for testing
‚îÇ       ‚îú‚îÄ‚îÄ fall-01-cam0.mp4
‚îÇ       ‚îú‚îÄ‚îÄ fall-01-cam1.mp4
‚îÇ       ‚îú‚îÄ‚îÄ image1.jpg
‚îÇ       ‚îî‚îÄ‚îÄ image2.jpg
‚îÇ
‚îî‚îÄ‚îÄ üìù **DOCUMENTATION**
    ‚îî‚îÄ‚îÄ WEB_UI_SUMMARY.md          # Web UI detailed documentation
```

---

## üìã **Y√äU C·∫¶U H·ªÜ TH·ªêNG**

### **üîß Y√™u C·∫ßu Ph·∫ßn C·ª©ng**

#### **Minimum Requirements:**
```
CPU: Intel i3/AMD Ryzen 3 (4 cores, 2.4GHz+)
RAM: 8GB DDR4
Webcam: USB 2.0 camera (720p+)
Network: Ethernet/WiFi cho API calls
OS: Windows 10/11, macOS 10.15+, Ubuntu 18.04+
```

#### **Recommended for VideoLLaMA3:**
```
CPU: Intel i7/AMD Ryzen 7 (8 cores, 3.0GHz+)
RAM: 16GB+ DDR4 
GPU: NVIDIA GTX 1660/RTX 3060 (6GB+ VRAM)
CUDA: 11.8+ ho·∫∑c 12.1+
Storage: 10GB+ free space
```

#### **Production Hospital Environment:**
```
CPU: Intel Xeon/AMD EPYC (16+ cores)
RAM: 32GB+ ECC
GPU: NVIDIA RTX 4090/A4000 (16GB+ VRAM)
Network: Gigabit Ethernet 
UPS: Backup power cho continuous operation
```

### **üì± Y√™u C·∫ßu Ph·∫ßn M·ªÅm**

#### **Core Requirements:**
- **Python**: 3.8+ (recommend 3.9-3.11)
- **OpenAI API Key**: B·∫Øt bu·ªôc ($5+ credit)
- **Camera Drivers**: USB/IP camera support
- **Network**: Internet cho API calls

#### **Optional but Recommended:**
- **Telegram Bot**: Instant notifications
- **Audio Drivers**: TTS support 
- **Docker**: Container deployment
- **GPU Drivers**: CUDA for VideoLLaMA3

---

## üì¶ **TH∆Ø VI·ªÜN V√Ä DEPENDENCIES**

### **üéØ Core Dependencies (requirements.txt)**
```python
# Computer Vision & Image Processing
opencv-python==4.8.1.78          # Camera capture, video processing
numpy==1.24.3                    # Numerical operations
Pillow==10.0.1                   # Image manipulation
imageio==2.34.0                  # GIF creation
imageio-ffmpeg==0.4.9            # Video format support

# AI & Language Models  
openai==1.12.0                   # VLM SmolVLM API
transformers==4.46.3             # VideoLLaMA3 model loading

# Web Interface
gradio>=5.31.0                   # Web UI framework

# Communication & Notifications
python-telegram-bot==20.7        # Telegram alerts

# System & Configuration
python-dotenv==1.0.0             # Environment variables
rich==13.7.0                     # Terminal formatting
pre-commit==4.2.0                # Code quality
```

### **ü§ñ VideoLLaMA3 Additional Requirements**
```python
torch>=2.0.0                     # PyTorch for model inference
torch-audio                      # Audio processing
transformers[torch]               # Transformer models
accelerate                       # Model optimization
bitsandbytes                     # Memory optimization
flash-attn                       # Attention optimization
```

### **üîä Audio TTS Dependencies**
```python
# Google TTS (Recommended)
gtts==2.4.0                      # Google Text-to-Speech
pygame==2.5.2                    # Audio playback

# Platform TTS Alternatives
pyttsx3                          # Cross-platform TTS
espeak-ng                        # Linux TTS engine
```

### **‚ö° Performance Optimization**
```python
# GPU Acceleration
torch[cuda]                      # CUDA support
tensorrt                         # NVIDIA optimization

# Async Processing  
asyncio                          # Built-in async
threading                       # Built-in threading
multiprocessing                 # Built-in multiprocessing
```

---

## üöÄ **H∆Ø·ªöNG D·∫™N CH·∫†Y PROJECT**

### **üì• B∆Ø·ªöC 1: INSTALLATION**

#### **Clone Project:**
```bash
git clone <repository-url>
cd llm-video-human-detection
```

#### **Setup Python Environment:**
```bash
# T·∫°o virtual environment (khuy·∫øn ngh·ªã)
python -m venv venv

# Activate environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

#### **Quick Setup v·ªõi Script:**
```bash
# Automatic setup
python src/setup.py

# Ho·∫∑c d√πng Makefile
make setup
```

### **‚öôÔ∏è B∆Ø·ªöC 2: CONFIGURATION**

#### **T·∫°o Environment File:**
```bash
# Copy template
cp env_template.txt .env

# Edit v·ªõi editor
nano .env  # ho·∫∑c vim, code, notepad++
```

#### **C·∫•u h√¨nh .env File:**
```env
# üîë REQUIRED: OpenAI API Key
OPENAI_API_KEY=sk-proj-your-actual-api-key-here

# üì± OPTIONAL: Telegram Notifications  
USE_TELE_ALERT=true
TELEGRAM_BOT_TOKEN=your_bot_token_from_botfather
TELEGRAM_CHAT_ID=your_chat_id

# üíæ OPTIONAL: Frame Saving
SAVE_ANALYSIS_FRAMES=true
SAVE_FORMAT=gif                  # images, gif, video, all

# üé• OPTIONAL: Camera Settings
CAMERA_INDEX=0                   # Default camera
MAX_FRAMES=5                     # Frames sent to AI
```

### **üß™ B∆Ø·ªöC 3: TESTING**

#### **Test System Components:**
```bash
# Comprehensive system test
python src/test_system.py

# Individual tests
make test                        # Using Makefile
```

#### **Test Output Example:**
```
=== Fall Detection System Tests ===
üìã Camera:
‚úÖ Camera working - Frame size: (480, 640, 3)

üìã OpenAI API:
‚úÖ OpenAI connection successful

üìã Telegram Bot:
‚úÖ Telegram connection successful

=== Test Results ===
Camera: ‚úÖ PASS
OpenAI API: ‚úÖ PASS  
Telegram Bot: ‚úÖ PASS

üéâ All tests passed! System ready to run.
```

### **üéØ B∆Ø·ªöC 4: CH·∫†Y H·ªÜ TH·ªêNG**

#### **üåê Option 1: Web UI (Recommended)**
```bash
# Quick start v·ªõi pre-checks
python start_web_ui.py

# Ho·∫∑c ch·∫°y tr·ª±c ti·∫øp
python main_ui.py
```

**Sau ƒë√≥ truy c·∫≠p:** http://localhost:7860

#### **üñ•Ô∏è Option 2: Console Version**
```bash
# Terminal interface
python main.py

# S·ª≠ d·ª•ng Makefile
make main
```

#### **üé¨ Option 3: Demo Analysis**
```bash
# Analyze sample videos
python demo.py

# Using Makefile
make demo
```

### **üîß B∆Ø·ªöC 5: ADVANCED SETUP**

#### **VideoLLaMA3 Model Setup:**
```bash
# Trong Web UI: v√†o tab "ü§ñ C·∫•u H√¨nh AI"
# Click "üì• T·∫£i Model" 
# Ho·∫∑c set detection method = "videollama3"

# Ki·ªÉm tra GPU memory:
nvidia-smi

# Free memory if needed:
python -c "import torch; torch.cuda.empty_cache()"
```

#### **Audio TTS Setup:**

**Linux:**
```bash
sudo apt-get install espeak-ng
# Ho·∫∑c
sudo apt-get install festival
```

**Windows:** (Windows SAPI c√≥ s·∫µn)
```powershell
# Install Google TTS
pip install gtts pygame
```

**macOS:** (say command c√≥ s·∫µn)  
```bash
# Install Google TTS
pip install gtts pygame
```

---

## üéÆ **H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG**

### **üåê Web UI Interface**

#### **Tab 1: üé• Camera & ƒêi·ªÅu Khi·ªÉn**
```
1. Ch·ªçn Camera Index (th∆∞·ªùng l√† 0)
2. Click "üöÄ Kh·ªüi ƒê·ªông" 
3. Xem live feed v√† status dashboard
4. Click "üõë D·ª´ng" ƒë·ªÉ stop
```

#### **Tab 2: üìÅ Upload Video**
```
1. Click "üìπ Ch·ªçn File Video" 
2. Upload MP4/AVI/MOV file
3. Click "üîç Ph√¢n T√≠ch Video"
4. Xem k·∫øt qu·∫£ trong "‚ÑπÔ∏è Th√¥ng Tin Video"
```

#### **Tab 3: üé¨ B·∫±ng Ch·ª©ng GIF**
```
1. Browse saved evidence GIFs
2. Select t·ª´ dropdown ƒë·ªÉ xem chi ti·∫øt
3. Review 5x speed GIF evidence
```

#### **Tab 4: ü§ñ C·∫•u H√¨nh AI**
```
1. Ch·ªçn detection method:
   - VLM SmolVLM (fast, online)
   - VideoLLaMA3 + OpenAI (accurate, hybrid)
2. Load/Unload VideoLLaMA3 model
3. Test audio warning system
```

### **üñ•Ô∏è Console Interface**

#### **Keyboard Controls:**
```
q       = Quit system
Ctrl+C  = Emergency stop
Space   = Manual analysis trigger
```

#### **Terminal Output:**
```
üîç Analysis logs every 5 seconds
üö® Fall alerts with Rich formatting  
üìä Real-time status table
üíæ Evidence saving confirmations
```

### **üé¨ Demo Mode**

#### **Analyze Sample Videos:**
```bash
python demo.py

# Available sample videos:
media/fall-01-cam0.mp4
media/fall-01-cam1.mp4
```

---

## ‚ö° **PERFORMANCE OPTIMIZATION**

### **üöÄ Speed Optimizations**

#### **OpenAI Mode (Fast):**
```python
analysis_interval = 3       # 3s intervals instead of 5s
max_frames = 3             # Fewer frames to AI
jpeg_quality = 60          # Lower quality for speed
```

#### **VideoLLaMA3 Mode (Accurate):**
```python
model_precision = "fp16"    # Half precision
max_frames = 64            # More frames for accuracy  
batch_processing = True    # Process multiple videos
```

### **üíæ Memory Management**

#### **RAM Optimization:**
```python
# Trong main_ui.py
frame_buffer_size = 5      # Reduce from 10 seconds
unload_model_when_idle = True
clear_cache_interval = 300 # 5 minutes
```

#### **VRAM Optimization:**
```python
# Trong videollama_detector.py
torch_dtype = torch.bfloat16  # Memory efficient
device_map = "auto"           # Auto GPU distribution
load_in_8bit = True          # Quantization
```

### **üåê Network Optimization**

#### **API Call Reduction:**
```python
max_frames = 3               # Reduce API payload
frame_compression = 0.7      # Higher compression
cooldown_period = 45         # Longer cooldown
```

#### **Offline Processing:**
```python
detection_method = "videollama3"  # Local processing
save_frames_locally = True        # Reduce uploads
batch_analysis = True             # Group API calls
```

---

## üîß **TROUBLESHOOTING**

### **‚ùå Common Issues & Solutions**

#### **Camera Issues:**
```bash
# Problem: Camera not detected
# Solution:
lsusb                       # Linux: List USB devices
Device Manager              # Windows: Check camera status
brew install ffmpeg         # macOS: Install video drivers

# Problem: Permission denied
sudo chmod 666 /dev/video0  # Linux: Camera permissions
```

#### **API Issues:**
```bash
# Problem: OpenAI API timeout  
# Solution:
export OPENAI_TIMEOUT=60    # Increase timeout
export MAX_RETRIES=3        # Retry failed calls

# Problem: Rate limiting
# Add delay between calls or upgrade API plan
```

#### **Memory Issues:**
```bash
# Problem: GPU out of memory
# Solution:
torch.cuda.empty_cache()     # Clear GPU memory
reduce max_frames            # Fewer frames to model
use model quantization       # 8-bit/4-bit precision
```

#### **Audio Issues:**
```bash
# Problem: TTS not working
# Linux:
sudo apt-get install espeak-ng alsa-utils

# Windows: 
# Check Windows Speech Platform in Control Panel

# macOS:
say "test"                   # Verify say command works
```

### **üêõ Debug Mode**

#### **Enable Detailed Logging:**
```python
# Trong main_ui.py
logging.basicConfig(level=logging.DEBUG)

# Environment variable
export DEBUG=1
```

#### **Performance Monitoring:**
```python
# Monitor GPU usage
nvidia-smi -l 1             # Continuous monitoring

# Monitor memory usage  
python -c "
import psutil
print(f'Memory: {psutil.virtual_memory().percent}%')
print(f'CPU: {psutil.cpu_percent()}%')
"
```

---

## üîí **PRODUCTION DEPLOYMENT**

### **üè• Hospital Environment Setup**

#### **Network Configuration:**
```bash
# Private network deployment
SERVER_HOST=192.168.1.100
SERVER_PORT=7860
ALLOWED_IPS=192.168.1.0/24

# Firewall rules
sudo ufw allow from 192.168.1.0/24 to any port 7860
```

#### **Service Configuration:**
```bash
# Systemd service (Linux)
sudo nano /etc/systemd/system/falldetection.service

[Unit]
Description=Fall Detection System
After=network.target

[Service]
Type=simple
User=falldetection
WorkingDirectory=/opt/falldetection
ExecStart=/opt/falldetection/venv/bin/python main_ui.py
Restart=always

[Install]
WantedBy=multi-user.target
```

#### **Container Deployment:**
```dockerfile
# Dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 7860

CMD ["python", "main_ui.py"]
```

### **üìä Monitoring & Alerts**

#### **System Health Checks:**
```python
# Health endpoint in main_ui.py
@app.route("/health")
def health_check():
    return {
        "status": "healthy",
        "camera": camera_status,
        "ai_model": model_status,
        "uptime": system_uptime
    }
```

#### **Log Aggregation:**
```bash
# Centralized logging
tail -f /var/log/falldetection/system.log
journalctl -u falldetection -f
```

H·ªá th·ªëng n√†y ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ **production-ready** v·ªõi kh·∫£ nƒÉng m·ªü r·ªông cao, ƒë·∫∑c bi·ªát ph√π h·ª£p cho m√¥i tr∆∞·ªùng b·ªánh vi·ªán c·∫ßn gi√°m s√°t t√© ng√£ 24/7 v·ªõi ƒë·ªô tin c·∫≠y v√† ch√≠nh x√°c cao.

```plaintext
llm-video-human-detection/
‚îú‚îÄ‚îÄ üéØ **ENTRY POINTS**
‚îÇ   ‚îú‚îÄ‚îÄ main.py                     # Console version - Terminal interface
‚îÇ   ‚îú‚îÄ‚îÄ main_ui.py                  # Web UI version - Gradio interface  
‚îÇ   ‚îú‚îÄ‚îÄ start_web_ui.py             # Quick start script v·ªõi pre-checks
‚îÇ   ‚îî‚îÄ‚îÄ demo.py                     # Demo analysis script
‚îÇ
‚îú‚îÄ‚îÄ üîß **CONFIGURATION FILES**
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt            # Python dependencies
‚îÇ   ‚îú‚îÄ‚îÄ env_template.txt           # Environment variables template
‚îÇ   ‚îú‚îÄ‚îÄ .env                       # Environment configuration (t·∫°o t·ª´ template)
‚îÇ   ‚îú‚îÄ‚îÄ Makefile                   # Utility commands
‚îÇ   ‚îî‚îÄ‚îÄ README.md                  # Main documentation
‚îÇ
‚îú‚îÄ‚îÄ üß† **SOURCE CODE MODULES**
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py            # System configuration & initialization
‚îÇ       ‚îú‚îÄ‚îÄ utils.py               # Frame processing & AI utilities  
‚îÇ       ‚îú‚îÄ‚îÄ videollama_detector.py # VideoLLaMA3 hybrid detector
‚îÇ       ‚îú‚îÄ‚îÄ audio_warning.py       # Text-to-speech alert system
‚îÇ       ‚îú‚îÄ‚îÄ alert_services.py      # Telegram notification service
‚îÇ       ‚îú‚îÄ‚îÄ setup.py               # System setup script
‚îÇ       ‚îî‚îÄ‚îÄ test_system.py         # Component testing script
‚îÇ
‚îú‚îÄ‚îÄ üé¨ **ALTERNATE IMPLEMENTATIONS**
‚îÇ   ‚îî‚îÄ‚îÄ vid_llama.py               # Standalone VideoLLaMA3 script
‚îÇ
‚îú‚îÄ‚îÄ üìÅ **DATA DIRECTORIES** (auto-created)
‚îÇ   ‚îú‚îÄ‚îÄ temp/                      # Temporary analysis files
‚îÇ   ‚îú‚îÄ‚îÄ evidence/                  # Evidence images/videos
‚îÇ   ‚îú‚îÄ‚îÄ evidence_gifs/             # GIF evidence with timestamps
‚îÇ   ‚îú‚îÄ‚îÄ analysis/                  # Analysis results by timestamp
‚îÇ   ‚îî‚îÄ‚îÄ media/                     # Sample videos for testing
‚îÇ       ‚îú‚îÄ‚îÄ fall-01-cam0.mp4
‚îÇ       ‚îú‚îÄ‚îÄ fall-01-cam1.mp4
‚îÇ       ‚îú‚îÄ‚îÄ image1.jpg
‚îÇ       ‚îî‚îÄ‚îÄ image2.jpg
‚îÇ
‚îî‚îÄ‚îÄ üìù **DOCUMENTATION**
    ‚îî‚îÄ‚îÄ WEB_UI_SUMMARY.md          # Web UI detailed documentation
```

```plaintext
CPU: Intel i3/AMD Ryzen 3 (4 cores, 2.4GHz+)
RAM: 8GB DDR4
Webcam: USB 2.0 camera (720p+)
Network: Ethernet/WiFi cho API calls
OS: Windows 10/11, macOS 10.15+, Ubuntu 18.04+
```

```plaintext
CPU: Intel i7/AMD Ryzen 7 (8 cores, 3.0GHz+)
RAM: 16GB+ DDR4 
GPU: NVIDIA GTX 1660/RTX 3060 (6GB+ VRAM)
CUDA: 11.8+ ho·∫∑c 12.1+
Storage: 10GB+ free space
```

```plaintext
CPU: Intel Xeon/AMD EPYC (16+ cores)
RAM: 32GB+ ECC
GPU: NVIDIA RTX 4090/A4000 (16GB+ VRAM)
Network: Gigabit Ethernet 
UPS: Backup power cho continuous operation
```

```python
# Computer Vision & Image Processing
opencv-python==4.8.1.78          # Camera capture, video processing
numpy==1.24.3                    # Numerical operations
Pillow==10.0.1                   # Image manipulation
imageio==2.34.0                  # GIF creation
imageio-ffmpeg==0.4.9            # Video format support

# AI & Language Models  
openai==1.12.0                   # VLM SmolVLM API
transformers==4.46.3             # VideoLLaMA3 model loading

# Web Interface
gradio>=5.31.0                   # Web UI framework

# Communication & Notifications
python-telegram-bot==20.7        # Telegram alerts

# System & Configuration
python-dotenv==1.0.0             # Environment variables
rich==13.7.0                     # Terminal formatting
pre-commit==4.2.0                # Code quality
```

```python
torch>=2.0.0                     # PyTorch for model inference
torch-audio                      # Audio processing
transformers[torch]               # Transformer models
accelerate                       # Model optimization
bitsandbytes                     # Memory optimization
flash-attn                       # Attention optimization
```

```python
# Google TTS (Recommended)
gtts==2.4.0                      # Google Text-to-Speech
pygame==2.5.2                    # Audio playback

# Platform TTS Alternatives
pyttsx3                          # Cross-platform TTS
espeak-ng                        # Linux TTS engine
```

```python
# GPU Acceleration
torch[cuda]                      # CUDA support
tensorrt                         # NVIDIA optimization

# Async Processing  
asyncio                          # Built-in async
threading                       # Built-in threading
multiprocessing                 # Built-in multiprocessing
```

```shellscript
git clone <repository-url>
cd llm-video-human-detection
```

```shellscript
# T·∫°o virtual environment (khuy·∫øn ngh·ªã)
python -m venv venv

# Activate environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

```shellscript
# Automatic setup
python src/setup.py

# Ho·∫∑c d√πng Makefile
make setup
```

```shellscript
# Copy template
cp env_template.txt .env

# Edit v·ªõi editor
nano .env  # ho·∫∑c vim, code, notepad++
```

```plaintext
# üîë REQUIRED: OpenAI API Key
OPENAI_API_KEY=sk-proj-your-actual-api-key-here

# üì± OPTIONAL: Telegram Notifications  
USE_TELE_ALERT=true
TELEGRAM_BOT_TOKEN=your_bot_token_from_botfather
TELEGRAM_CHAT_ID=your_chat_id

# üíæ OPTIONAL: Frame Saving
SAVE_ANALYSIS_FRAMES=true
SAVE_FORMAT=gif                  # images, gif, video, all

# üé• OPTIONAL: Camera Settings
CAMERA_INDEX=0                   # Default camera
MAX_FRAMES=5                     # Frames sent to AI
```

```shellscript
# Comprehensive system test
python src/test_system.py

# Individual tests
make test                        # Using Makefile
```

```plaintext
=== Fall Detection System Tests ===
üìã Camera:
‚úÖ Camera working - Frame size: (480, 640, 3)

üìã OpenAI API:
‚úÖ OpenAI connection successful

üìã Telegram Bot:
‚úÖ Telegram connection successful

=== Test Results ===
Camera: ‚úÖ PASS
OpenAI API: ‚úÖ PASS  
Telegram Bot: ‚úÖ PASS

üéâ All tests passed! System ready to run.
```

```shellscript
# Quick start v·ªõi pre-checks
python start_web_ui.py

# Ho·∫∑c ch·∫°y tr·ª±c ti·∫øp
python main_ui.py
```

```shellscript
# Terminal interface
python main.py

# S·ª≠ d·ª•ng Makefile
make main
```

```shellscript
# Analyze sample videos
python demo.py

# Using Makefile
make demo
```

```shellscript
# Trong Web UI: v√†o tab "ü§ñ C·∫•u H√¨nh AI"
# Click "üì• T·∫£i Model" 
# Ho·∫∑c set detection method = "videollama3"

# Ki·ªÉm tra GPU memory:
nvidia-smi

# Free memory if needed:
python -c "import torch; torch.cuda.empty_cache()"
```

```shellscript
sudo apt-get install espeak-ng
# Ho·∫∑c
sudo apt-get install festival
```

```powershell
# Install Google TTS
pip install gtts pygame
```

```shellscript
# Install Google TTS
pip install gtts pygame
```

```plaintext
1. Ch·ªçn Camera Index (th∆∞·ªùng l√† 0)
2. Click "üöÄ Kh·ªüi ƒê·ªông" 
3. Xem live feed v√† status dashboard
4. Click "üõë D·ª´ng" ƒë·ªÉ stop
```

```plaintext
1. Click "üìπ Ch·ªçn File Video" 
2. Upload MP4/AVI/MOV file
3. Click "üîç Ph√¢n T√≠ch Video"
4. Xem k·∫øt qu·∫£ trong "‚ÑπÔ∏è Th√¥ng Tin Video"
```

```plaintext
1. Browse saved evidence GIFs
2. Select t·ª´ dropdown ƒë·ªÉ xem chi ti·∫øt
3. Review 5x speed GIF evidence
```

```plaintext
1. Ch·ªçn detection method:
   - VLM SmolVLM (fast, online)
   - VideoLLaMA3 + OpenAI (accurate, hybrid)
2. Load/Unload VideoLLaMA3 model
3. Test audio warning system
```

```plaintext
q       = Quit system
Ctrl+C  = Emergency stop
Space   = Manual analysis trigger
```

```plaintext
üîç Analysis logs every 5 seconds
üö® Fall alerts with Rich formatting  
üìä Real-time status table
üíæ Evidence saving confirmations
```

```shellscript
python demo.py

# Available sample videos:
media/fall-01-cam0.mp4
media/fall-01-cam1.mp4
```

```python
analysis_interval = 3       # 3s intervals instead of 5s
max_frames = 3             # Fewer frames to AI
jpeg_quality = 60          # Lower quality for speed
```

```python
model_precision = "fp16"    # Half precision
max_frames = 64            # More frames for accuracy  
batch_processing = True    # Process multiple videos
```

```python
# Trong main_ui.py
frame_buffer_size = 5      # Reduce from 10 seconds
unload_model_when_idle = True
clear_cache_interval = 300 # 5 minutes
```

```python
# Trong videollama_detector.py
torch_dtype = torch.bfloat16  # Memory efficient
device_map = "auto"           # Auto GPU distribution
load_in_8bit = True          # Quantization
```

```python
max_frames = 3               # Reduce API payload
frame_compression = 0.7      # Higher compression
cooldown_period = 45         # Longer cooldown
```

```python
detection_method = "videollama3"  # Local processing
save_frames_locally = True        # Reduce uploads
batch_analysis = True             # Group API calls
```

```shellscript
# Problem: Camera not detected
# Solution:
lsusb                       # Linux: List USB devices
Device Manager              # Windows: Check camera status
brew install ffmpeg         # macOS: Install video drivers

# Problem: Permission denied
sudo chmod 666 /dev/video0  # Linux: Camera permissions
```

```shellscript
# Problem: OpenAI API timeout  
# Solution:
export OPENAI_TIMEOUT=60    # Increase timeout
export MAX_RETRIES=3        # Retry failed calls

# Problem: Rate limiting
# Add delay between calls or upgrade API plan
```

```shellscript
# Problem: GPU out of memory
# Solution:
torch.cuda.empty_cache()     # Clear GPU memory
reduce max_frames            # Fewer frames to model
use model quantization       # 8-bit/4-bit precision
```

```shellscript
# Problem: TTS not working
# Linux:
sudo apt-get install espeak-ng alsa-utils

# Windows: 
# Check Windows Speech Platform in Control Panel

# macOS:
say "test"                   # Verify say command works
```

```python
# Trong main_ui.py
logging.basicConfig(level=logging.DEBUG)

# Environment variable
export DEBUG=1
```

```python
# Monitor GPU usage
nvidia-smi -l 1             # Continuous monitoring

# Monitor memory usage  
python -c "
import psutil
print(f'Memory: {psutil.virtual_memory().percent}%')
print(f'CPU: {psutil.cpu_percent()}%')
"
```

```shellscript
# Private network deployment
SERVER_HOST=192.168.1.100
SERVER_PORT=7860
ALLOWED_IPS=192.168.1.0/24

# Firewall rules
sudo ufw allow from 192.168.1.0/24 to any port 7860
```

```shellscript
# Systemd service (Linux)
sudo nano /etc/systemd/system/falldetection.service

[Unit]
Description=Fall Detection System
After=network.target

[Service]
Type=simple
User=falldetection
WorkingDirectory=/opt/falldetection
ExecStart=/opt/falldetection/venv/bin/python main_ui.py
Restart=always

[Install]
WantedBy=multi-user.target
```

```dockerfile
# Dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 7860

CMD ["python", "main_ui.py"]
```

```python
# Health endpoint in main_ui.py
@app.route("/health")
def health_check():
    return {
        "status": "healthy",
        "camera": camera_status,
        "ai_model": model_status,
        "uptime": system_uptime
    }
```

```shellscript
# Centralized logging
tail -f /var/log/falldetection/system.log
journalctl -u falldetection -f
```

