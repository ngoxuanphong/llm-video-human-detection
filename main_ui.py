import asyncio
import json
import os
import queue
import threading
import time
from datetime import datetime

import cv2
import gradio as gr
import numpy as np
from PIL import Image

from src import (
    OPENAI_CLIENT,
    SAVE_ANALYSIS_FRAMES,
    SAVE_FORMAT,
    TELEGRAM_BOT,
    USE_TELE_ALERT,
    alert_services,
)
from src.utils import frames_to_base64, prepare_messages, save_analysis_frames_to_temp


class FallDetectionWebUI:
    def __init__(self):
        # Camera and detection settings
        self.camera = None
        self.is_running = False
        self.analysis_interval = 5
        self.frame_buffer = []
        self.last_analysis_time = 0
        self.fall_detected_cooldown = 30
        self.last_fall_alert = 0
        self.frame_count = 0
        self.analysis_count = 0
        self.start_time = time.time()

        # UI specific
        self.current_frame = None
        self.alert_history = []
        self.system_logs = []
        self.status_data = {}
        self.ui_update_queue = queue.Queue()

        # Status tracking
        self.camera_status = "Kh√¥ng ho·∫°t ƒë·ªông"
        self.last_analysis_result = "Ch∆∞a c√≥ ph√¢n t√≠ch"

        # Video upload processing
        self.upload_processing = False
        self.upload_progress = 0
        self.uploaded_video_path = None

        # Evidence storage
        self.evidence_gifs = []  # Store paths to saved GIF evidence

    def initialize_camera(self, camera_index=0):
        """Initialize camera capture"""
        try:
            if self.camera:
                self.camera.release()

            self.camera = cv2.VideoCapture(camera_index)
            if not self.camera.isOpened():
                raise Exception(f"Kh√¥ng th·ªÉ m·ªü camera {camera_index}")

            # Set camera properties
            self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.camera.set(cv2.CAP_PROP_FPS, 30)

            self.camera_status = "Ho·∫°t ƒë·ªông"
            self.add_log("‚úì Camera ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng", "success")
            return True

        except Exception as e:
            self.camera_status = "L·ªói"
            self.add_log(f"‚úó Kh√¥ng th·ªÉ kh·ªüi t·∫°o camera: {e}", "error")
            return False

    def add_log(self, message, log_type="info"):
        """Add log message with timestamp"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_entry = {"time": timestamp, "message": message, "type": log_type}
        self.system_logs.append(log_entry)
        # Keep only last 100 logs
        if len(self.system_logs) > 100:
            self.system_logs.pop(0)

    def capture_frames(self):
        """Continuously capture frames from camera"""
        while self.is_running and self.camera:
            ret, frame = self.camera.read()
            if not ret:
                self.add_log("‚ö† Kh√¥ng th·ªÉ ch·ª•p khung h√¨nh", "warning")
                continue

            # Add timestamp to frame
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            cv2.putText(frame, timestamp, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

            # Store frame with timestamp
            current_time = time.time()
            self.frame_count += 1
            self.frame_buffer.append({"frame": frame, "timestamp": current_time})

            # Keep only recent frames (last 10 seconds)
            self.frame_buffer = [f for f in self.frame_buffer if current_time - f["timestamp"] < 10]

            # Update current frame for UI
            self.current_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

            # Check for analysis trigger
            if current_time - self.last_analysis_time >= self.analysis_interval:
                threading.Thread(target=self.analyze_frames, daemon=True).start()
                self.last_analysis_time = current_time

            time.sleep(0.03)  # ~30 FPS

    def analyze_frames(self):
        """Analyze recent frames for fall detection using OpenAI"""
        if not self.frame_buffer:
            return

        try:
            self.analysis_count += 1
            self.add_log(f"üîç B·∫Øt ƒë·∫ßu ph√¢n t√≠ch l·∫ßn {self.analysis_count}...", "info")

            # Get recent frames
            recent_frames = self.frame_buffer.copy()

            # Save analysis frames if enabled
            if SAVE_ANALYSIS_FRAMES:
                threading.Thread(target=save_analysis_frames_to_temp, args=([recent_frames])).start()

            base64_frames = frames_to_base64(recent_frames)

            if not base64_frames:
                return

            # Call OpenAI API
            response = OPENAI_CLIENT.chat.completions.create(model="gpt-4o-mini", messages=prepare_messages(base64_frames), max_tokens=150)

            analysis_result = response.choices[0].message.content.strip()
            self.last_analysis_result = analysis_result
            self.add_log(f"üìä K·∫øt qu·∫£ ph√¢n t√≠ch: {analysis_result}", "info")

            # Check for fall detection (Vietnamese)
            if analysis_result.startswith("PH√ÅT_HI·ªÜN_T√â_NG√É"):
                self.handle_fall_detection(analysis_result)

        except Exception as e:
            self.add_log(f"‚ùå L·ªói ph√¢n t√≠ch: {e}", "error")

    def handle_fall_detection(self, analysis_result):
        """Handle detected fall - send alerts"""
        current_time = time.time()

        # Check cooldown to prevent spam
        if current_time - self.last_fall_alert < self.fall_detected_cooldown:
            self.add_log("‚è≥ Ph√°t hi·ªán t√© ng√£ nh∆∞ng v·∫´n trong th·ªùi gian ch·ªù", "warning")
            return

        self.last_fall_alert = current_time
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        # Add to alert history
        alert_data = {
            "timestamp": timestamp,
            "details": analysis_result,
            "frame_count": len(self.frame_buffer),
            "evidence_saved": SAVE_ANALYSIS_FRAMES,
            "source": "Live Camera",
        }
        self.alert_history.append(alert_data)

        # Log the alert
        self.add_log(f"üö® PH√ÅT HI·ªÜN T√â NG√É: {analysis_result}", "alert")

        # Save evidence as GIF
        try:
            gif_path = self.save_evidence_gif(self.frame_buffer, timestamp, "Live Camera")
            if gif_path:
                alert_data["gif_evidence"] = gif_path
                self.evidence_gifs.append({"path": gif_path, "timestamp": timestamp, "source": "Live Camera", "details": analysis_result})
                self.add_log(f"üíæ ƒê√£ l∆∞u b·∫±ng ch·ª©ng GIF: {os.path.basename(gif_path)}", "success")
        except Exception as e:
            self.add_log(f"‚ùå L·ªói l∆∞u GIF: {e}", "error")

        # Send Telegram notification only if enabled
        if TELEGRAM_BOT and USE_TELE_ALERT:
            asyncio.create_task(alert_services.send_telegram_alert(analysis_result, timestamp, self.frame_buffer))
            self.add_log("üì± Th√¥ng b√°o Telegram ƒë√£ g·ª≠i", "success")
        else:
            self.add_log("‚Ñπ B·ªè qua th√¥ng b√°o Telegram (ƒë√£ t·∫Øt ho·∫∑c ch∆∞a c·∫•u h√¨nh)", "info")

        # Save current frame as evidence (original format)
        if self.frame_buffer:
            threading.Thread(target=save_analysis_frames_to_temp, args=([self.frame_buffer])).start()

    def start_detection(self, camera_index):
        """Start the fall detection system"""
        if self.is_running:
            return "‚ùå H·ªá th·ªëng ƒë√£ ƒëang ch·∫°y!", self.get_status_info()

        if not self.initialize_camera(camera_index):
            return "‚ùå Kh√¥ng th·ªÉ kh·ªüi t·∫°o camera!", self.get_status_info()

        self.is_running = True
        self.start_time = time.time()
        self.add_log("üöÄ H·ªá th·ªëng ph√°t hi·ªán t√© ng√£ ƒë√£ kh·ªüi ƒë·ªông", "success")

        # Start capture thread
        threading.Thread(target=self.capture_frames, daemon=True).start()

        return "‚úÖ H·ªá th·ªëng ƒë√£ kh·ªüi ƒë·ªông th√†nh c√¥ng!", self.get_status_info()

    def stop_detection(self):
        """Stop the fall detection system"""
        if not self.is_running:
            return "‚ùå H·ªá th·ªëng ch∆∞a ch·∫°y!", self.get_status_info()

        self.is_running = False
        self.camera_status = "ƒê√£ d·ª´ng"

        if self.camera:
            self.camera.release()
            self.camera = None

        self.add_log("üõë H·ªá th·ªëng ph√°t hi·ªán t√© ng√£ ƒë√£ d·ª´ng", "info")
        return "‚úÖ H·ªá th·ªëng ƒë√£ d·ª´ng!", self.get_status_info()

    def get_current_frame(self):
        """Get current frame for display"""
        if self.current_frame is not None:
            return Image.fromarray(self.current_frame)
        else:
            # Return a placeholder image
            placeholder = np.zeros((480, 640, 3), dtype=np.uint8)
            cv2.putText(placeholder, "Camera chua khoi dong", (150, 240), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            return Image.fromarray(placeholder)

    def get_status_info(self):
        """Get system status information"""
        uptime = time.strftime("%H:%M:%S", time.gmtime(time.time() - self.start_time))

        status_text = f"""
üìä **TR·∫†NG TH√ÅI H·ªÜ TH·ªêNG**

üé• **Camera:** {self.camera_status}\n
üîç **L·∫ßn ph√¢n t√≠ch:** {self.analysis_count}\n
üì± **G·ª≠i Tin Nh·∫Øn:** {'B·∫≠t' if USE_TELE_ALERT else 'T·∫Øt'}\n
üíæ **L∆∞u Frames:** {'B·∫≠t (' + SAVE_FORMAT.upper() + ')' if SAVE_ANALYSIS_FRAMES else 'T·∫Øt'}\n
‚è∞ **Th·ªùi gian ho·∫°t ƒë·ªông:** {uptime}\n
üîÑ **Chu k·ª≥:** {self.analysis_interval}s\n
üìà **Khung h√¨nh/Buffer Frames:** {self.frame_count} / {len(self.frame_buffer)}\n
üö® **C·∫£nh b√°o:** {len(self.alert_history)}\n

üìã **K·∫øt qu·∫£ ph√¢n t√≠ch g·∫ßn nh·∫•t:**
{self.last_analysis_result}
        """
        return status_text

    def get_logs_display(self):
        """Get formatted logs for display"""
        if not self.system_logs:
            return "Ch∆∞a c√≥ log n√†o..."

        log_text = ""
        for log in self.system_logs[-30:]:  # Show last 30 logs
            emoji = {"info": "‚ÑπÔ∏è", "success": "‚úÖ", "warning": "‚ö†Ô∏è", "error": "‚ùå", "alert": "üö®"}
            icon = emoji.get(log["type"], "üìù")
            log_text += f"[{log['time']}] {icon} {log['message']}\n"

        return log_text

    def get_alert_history_display(self):
        """Get formatted alert history for display"""
        if not self.alert_history:
            return "Ch∆∞a c√≥ c·∫£nh b√°o n√†o..."

        alert_text = ""
        for i, alert in enumerate(reversed(self.alert_history[-10:])):  # Show last 10 alerts
            alert_text += f"""
**C·∫£nh b√°o #{len(self.alert_history) - i}**
üïê Th·ªùi gian: {alert['timestamp']}
üìù Chi ti·∫øt: {alert['details']}
üìä Frames: {alert['frame_count']}
üíæ B·∫±ng ch·ª©ng: {'ƒê√£ l∆∞u' if alert['evidence_saved'] else 'Kh√¥ng l∆∞u'}
---
            """

        return alert_text

    def process_uploaded_video(self, video_path):
        """Process uploaded video file for fall detection"""
        if not video_path:
            return "‚ùå Kh√¥ng c√≥ video ƒë∆∞·ª£c upload!", "Vui l√≤ng ch·ªçn file video"

        if self.upload_processing:
            return "‚ùå ƒêang x·ª≠ l√Ω video kh√°c!", "Vui l√≤ng ch·ªù ho√†n th√†nh"

        self.upload_processing = True
        self.upload_progress = 0
        self.uploaded_video_path = video_path

        try:
            self.add_log(f"üìÅ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω video: {os.path.basename(video_path)}", "info")

            # Open video file
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                raise Exception("Kh√¥ng th·ªÉ m·ªü file video")

            # Get video properties
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            duration = total_frames / fps if fps > 0 else 0

            self.add_log(f"üìä Video info: {total_frames} frames, {fps:.1f} FPS, {duration:.1f}s", "info")

            # Process video in chunks (analyze every 5 seconds)
            analysis_interval_frames = int(fps * 5) if fps > 0 else 150  # 5 seconds worth of frames

            frame_buffer = []
            frame_count = 0
            analysis_count = 0

            while True:
                ret, frame = cap.read()
                if not ret:
                    break

                frame_count += 1
                current_time = frame_count / fps if fps > 0 else frame_count * 0.033

                # Add frame to buffer
                frame_buffer.append({"frame": frame, "timestamp": current_time})

                # Update progress
                self.upload_progress = int((frame_count / total_frames) * 100) if total_frames > 0 else 0

                # Analyze when we have enough frames or at the end
                if len(frame_buffer) >= analysis_interval_frames or frame_count == total_frames:
                    analysis_count += 1

                    try:
                        # Analyze frames for fall detection
                        analysis_result = self.analyze_video_frames(frame_buffer, analysis_count, video_path)

                        # Check for fall detection
                        if analysis_result and analysis_result.startswith("PH√ÅT_HI·ªÜN_T√â_NG√É"):
                            self.handle_video_fall_detection(analysis_result, frame_buffer, current_time, video_path)

                    except Exception as e:
                        self.add_log(f"‚ùå L·ªói ph√¢n t√≠ch chunk {analysis_count}: {e}", "error")

                    # Reset buffer
                    frame_buffer = []

            cap.release()
            self.upload_processing = False
            self.upload_progress = 100

            result_msg = f"‚úÖ Ho√†n th√†nh x·ª≠ l√Ω video! ƒê√£ ph√¢n t√≠ch {analysis_count} ƒëo·∫°n video"
            self.add_log(result_msg, "success")

            return result_msg, f"Video: {os.path.basename(video_path)}\nFrames: {frame_count}\nPh√¢n t√≠ch: {analysis_count} ƒëo·∫°n"

        except Exception as e:
            self.upload_processing = False
            error_msg = f"‚ùå L·ªói x·ª≠ l√Ω video: {e}"
            self.add_log(error_msg, "error")
            return error_msg, "X·ª≠ l√Ω th·∫•t b·∫°i"

    def analyze_video_frames(self, frame_buffer, analysis_count, source_video):
        """Analyze frames from uploaded video"""
        if not frame_buffer:
            return None

        try:
            self.add_log(f"üîç Ph√¢n t√≠ch ƒëo·∫°n video {analysis_count} ({len(frame_buffer)} frames)...", "info")

            # Convert frames to base64 (sample frames to avoid too many)
            sample_frames = frame_buffer[:: max(1, len(frame_buffer) // 5)]  # Sample max 5 frames
            base64_frames = frames_to_base64(sample_frames)

            if not base64_frames:
                return None

            # Call OpenAI API
            response = OPENAI_CLIENT.chat.completions.create(model="gpt-4o-mini", messages=prepare_messages(base64_frames), max_tokens=150)

            analysis_result = response.choices[0].message.content.strip()
            self.add_log(f"üìä K·∫øt qu·∫£ ph√¢n t√≠ch ƒëo·∫°n {analysis_count}: {analysis_result}", "info")

            return analysis_result

        except Exception as e:
            self.add_log(f"‚ùå L·ªói ph√¢n t√≠ch video frames: {e}", "error")
            return None

    def handle_video_fall_detection(self, analysis_result, frame_buffer, timestamp, source_video):
        """Handle fall detection from uploaded video"""
        detection_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        # Create alert data for video
        alert_data = {
            "timestamp": detection_time,
            "details": analysis_result,
            "frame_count": len(frame_buffer),
            "evidence_saved": True,
            "source": f"Video: {os.path.basename(source_video)}",
            "video_timestamp": f"{timestamp:.1f}s",
        }

        self.alert_history.append(alert_data)
        self.add_log(f"üö® PH√ÅT HI·ªÜN T√â NG√É TRONG VIDEO: {analysis_result} t·∫°i {timestamp:.1f}s", "alert")

        # Save evidence as GIF
        try:
            gif_path = self.save_evidence_gif(frame_buffer, detection_time, source_video)
            if gif_path:
                alert_data["gif_evidence"] = gif_path
                self.evidence_gifs.append({"path": gif_path, "timestamp": detection_time, "source": os.path.basename(source_video), "details": analysis_result})
                self.add_log(f"üíæ ƒê√£ l∆∞u b·∫±ng ch·ª©ng GIF: {os.path.basename(gif_path)}", "success")
        except Exception as e:
            self.add_log(f"‚ùå L·ªói l∆∞u GIF: {e}", "error")

        # Send Telegram notification if enabled
        if TELEGRAM_BOT and USE_TELE_ALERT:
            try:
                asyncio.create_task(
                    alert_services.send_telegram_alert(
                        f"üé¨ {analysis_result} (Video: {os.path.basename(source_video)} t·∫°i {timestamp:.1f}s)", detection_time, frame_buffer
                    )
                )
                self.add_log("üì± Th√¥ng b√°o Telegram ƒë√£ g·ª≠i", "success")
            except Exception as e:
                self.add_log(f"‚ùå L·ªói g·ª≠i Telegram: {e}", "error")

    def save_evidence_gif(self, frame_buffer, timestamp, source_info):
        """Save frame buffer as GIF evidence"""
        try:
            # Create evidence directory if not exists
            evidence_dir = "evidence_gifs"
            os.makedirs(evidence_dir, exist_ok=True)

            # Generate filename
            safe_timestamp = timestamp.replace(":", "-").replace(" ", "_")
            filename = f"fall_evidence_{safe_timestamp}.gif"
            gif_path = os.path.join(evidence_dir, filename)

            # Convert frames to PIL Images
            pil_frames = []
            for frame_data in frame_buffer[::2]:  # Skip every other frame for smaller GIF
                frame = frame_data["frame"]
                # Resize frame for smaller file size
                height, width = frame.shape[:2]
                new_width = min(320, width)
                new_height = int(height * (new_width / width))
                resized_frame = cv2.resize(frame, (new_width, new_height))
                pil_frame = Image.fromarray(cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB))
                pil_frames.append(pil_frame)

            # Save as GIF
            if pil_frames:
                pil_frames[0].save(gif_path, save_all=True, append_images=pil_frames[1:], duration=200, loop=0)  # 200ms per frame
                return gif_path

        except Exception as e:
            self.add_log(f"‚ùå L·ªói t·∫°o GIF: {e}", "error")
            return None

    def get_evidence_gifs_display(self):
        """Get list of evidence GIFs for display"""
        if not self.evidence_gifs:
            return "Ch∆∞a c√≥ b·∫±ng ch·ª©ng GIF n√†o...", []

        display_text = f"üìÅ **C√ì {len(self.evidence_gifs)} B·∫∞NG CH·ª®NG GIF**\n\n"

        gif_paths = []
        for i, evidence in enumerate(reversed(self.evidence_gifs[-10:])):  # Show last 10
            display_text += f"""
**GIF #{len(self.evidence_gifs) - i}**
üïê Th·ªùi gian: {evidence['timestamp']}
üìÅ Ngu·ªìn: {evidence['source']}
üìù Chi ti·∫øt: {evidence['details']}
üìÑ File: {os.path.basename(evidence['path'])}
---
            """
            gif_paths.append(evidence["path"])

        return display_text, gif_paths

    def get_upload_progress(self):
        """Get current upload processing progress"""
        if not self.upload_processing:
            return "S·∫µn s√†ng upload video", 0
        return f"ƒêang x·ª≠ l√Ω video... {self.upload_progress}%", self.upload_progress


# Initialize the system
fall_system = FallDetectionWebUI()


def create_interface():
    """Create the Gradio interface"""

    with gr.Blocks(
        title="üè• H·ªá Th·ªëng Ph√°t Hi·ªán T√© Ng√£",
        theme=gr.themes.Soft(),
        css="""
        .alert-box { background-color: #ffebee; border-left: 4px solid #f44336; padding: 10px; }
        .success-box { background-color: #e8f5e8; border-left: 4px solid #4caf50; padding: 10px; }
        .info-box { background-color: #e3f2fd; border-left: 4px solid #2196f3; padding: 10px; }
        """,
    ) as demo:

        gr.HTML(
            """
        <div style="text-align: center; margin-bottom: 20px;">
            <h1>üè• H·ªÜ TH·ªêNG PH√ÅT HI·ªÜN T√â NG√É B·ªÜNH VI·ªÜN</h1>
            <p style="font-size: 16px; color: #666;">
                H·ªá th·ªëng AI ph√°t hi·ªán t√© ng√£ th·ªùi gian th·ª±c s·ª≠ d·ª•ng Vision Language Model
            </p>
        </div>
        """
        )

        with gr.Tab("üé• Camera & ƒêi·ªÅu Khi·ªÉn"):
            with gr.Row():
                with gr.Column(scale=2):
                    camera_feed = gr.Image(label="üìπ Camera Feed", type="pil", height=400, show_label=True)

                    with gr.Row():
                        camera_index = gr.Number(label="Ch·ªâ s·ªë Camera", value=0, precision=0, minimum=0, maximum=10)
                        start_btn = gr.Button("üöÄ Kh·ªüi ƒê·ªông", variant="primary", size="lg")
                        stop_btn = gr.Button("üõë D·ª´ng", variant="secondary", size="lg")

                with gr.Column(scale=1):
                    status_display = gr.Markdown(label="üìä Tr·∫°ng Th√°i H·ªá Th·ªëng", value=fall_system.get_status_info())

                    control_output = gr.Textbox(label="üì¢ Th√¥ng B√°o H·ªá Th·ªëng", value="S·∫µn s√†ng kh·ªüi ƒë·ªông...", interactive=False)

        with gr.Tab("üìã Nh·∫≠t K√Ω H·ªá Th·ªëng"):
            logs_display = gr.Textbox(label="üìù System Logs (30 m·ª•c g·∫ßn nh·∫•t)", value=fall_system.get_logs_display(), lines=30, interactive=False, max_lines=25)

            refresh_logs_btn = gr.Button("üîÑ C·∫≠p Nh·∫≠t Logs", size="sm")

        with gr.Tab("üö® L·ªãch S·ª≠ C·∫£nh B√°o"):
            alert_display = gr.Markdown(label="üö® L·ªãch S·ª≠ T√© Ng√£ (10 c·∫£nh b√°o g·∫ßn nh·∫•t)", value=fall_system.get_alert_history_display())

            refresh_alerts_btn = gr.Button("üîÑ C·∫≠p Nh·∫≠t C·∫£nh B√°o", size="sm")

            with gr.Row():
                clear_alerts_btn = gr.Button("üóëÔ∏è X√≥a L·ªãch S·ª≠", variant="secondary")
                export_alerts_btn = gr.Button("üìÅ Xu·∫•t B√°o C√°o", variant="primary")

        with gr.Tab("üìÅ Upload Video"):
            gr.HTML(
                """
            <div class="info-box">
                <h3>üìÅ Ph√¢n T√≠ch Video T·ª´ File</h3>
                <p>Upload video t·ª´ thi·∫øt b·ªã ƒë·ªÉ ph√¢n t√≠ch t√© ng√£. H·ªó tr·ª£ c√°c ƒë·ªãnh d·∫°ng: MP4, AVI, MOV, MKV</p>
            </div>
            """
            )

            with gr.Row():
                with gr.Column(scale=2):
                    video_upload = gr.File(label="üìπ Ch·ªçn File Video", file_types=["video"], type="filepath")

                    upload_btn = gr.Button("üîç Ph√¢n T√≠ch Video", variant="primary", size="lg")

                    gr.Progress()
                    upload_status = gr.Textbox(label="üìä Tr·∫°ng Th√°i X·ª≠ L√Ω", value="Ch∆∞a c√≥ video ƒë∆∞·ª£c upload...", interactive=False)

                with gr.Column(scale=1):
                    upload_info = gr.Textbox(label="‚ÑπÔ∏è Th√¥ng Tin Video", value="Ch∆∞a ch·ªçn video...", interactive=False, lines=10)

            gr.HTML(
                """
            <div class="alert-box">
                <h4>‚ö†Ô∏è L∆∞u √ù Quan Tr·ªçng</h4>
                <ul>
                    <li>Video s·∫Ω ƒë∆∞·ª£c ph√¢n t√≠ch t·ª´ng ƒëo·∫°n 5 gi√¢y</li>
                    <li>Qu√° tr√¨nh c√≥ th·ªÉ m·∫•t th·ªùi gian t√πy theo ƒë·ªô d√†i video</li>
                    <li>K·∫øt qu·∫£ s·∫Ω hi·ªÉn th·ªã trong l·ªãch s·ª≠ c·∫£nh b√°o</li>
                    <li>GIF b·∫±ng ch·ª©ng s·∫Ω ƒë∆∞·ª£c t·ª± ƒë·ªông t·∫°o khi ph√°t hi·ªán t√© ng√£</li>
                </ul>
            </div>
            """
            )

        with gr.Tab("üé¨ B·∫±ng Ch·ª©ng GIF"):
            gr.HTML(
                """
            <div class="success-box">
                <h3>üé¨ B·∫±ng Ch·ª©ng T√© Ng√£ (GIF)</h3>
                <p>Xem c√°c GIF b·∫±ng ch·ª©ng ƒë√£ ƒë∆∞·ª£c l∆∞u khi ph√°t hi·ªán t√© ng√£</p>
            </div>
            """
            )

            with gr.Row():
                with gr.Column(scale=1):
                    evidence_list = gr.Markdown(label="üìã Danh S√°ch B·∫±ng Ch·ª©ng", value=fall_system.get_evidence_gifs_display()[0])

                    with gr.Row():
                        refresh_evidence_btn = gr.Button("üîÑ C·∫≠p Nh·∫≠t", size="sm")
                        clear_evidence_btn = gr.Button("üóëÔ∏è X√≥a T·∫•t C·∫£", variant="secondary", size="sm")

                with gr.Column(scale=2):
                    evidence_gallery = gr.Gallery(label="üé¨ GIF B·∫±ng Ch·ª©ng", show_label=True, elem_id="evidence_gallery", columns=2, rows=3, height="auto")

            gr.HTML(
                """
            <div class="info-box">
                <h4>üìã H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng</h4>
                <ul>
                    <li>Click v√†o GIF trong gallery ƒë·ªÉ xem chi ti·∫øt</li>
                    <li>GIF ƒë∆∞·ª£c t·ª± ƒë·ªông t·∫°o khi ph√°t hi·ªán t√© ng√£</li>
                    <li>M·ªói GIF ch·ª©a kho·∫£nh kh·∫Øc tr∆∞·ªõc v√† sau khi t√© ng√£</li>
                    <li>GIF ƒë∆∞·ª£c l∆∞u trong th∆∞ m·ª•c <code>evidence_gifs/</code></li>
                </ul>
            </div>
            """
            )

        with gr.Tab("‚öôÔ∏è C·∫•u H√¨nh"):
            gr.HTML(
                """
            <div class="info-box">
                <h3>üîß C·∫•u H√¨nh H·ªá Th·ªëng</h3>
                <p>C√°c c·∫•u h√¨nh ƒë∆∞·ª£c ƒë·ªçc t·ª´ file <code>.env</code>. Sau khi thay ƒë·ªïi, vui l√≤ng kh·ªüi ƒë·ªông l·∫°i ·ª©ng d·ª•ng.</p>
            </div>
            """
            )

            with gr.Row():
                with gr.Column():
                    gr.Markdown(
                        """

                    ### üì± C·∫•u H√¨nh Telegram
                    - **USE_TELE_ALERT**: true/false (m·∫∑c ƒë·ªãnh: false)
                    - **TELEGRAM_BOT_TOKEN**: Token bot Telegram
                    - **TELEGRAM_CHAT_ID**: ID chat nh·∫≠n th√¥ng b√°o

                    ### üíæ C·∫•u H√¨nh L∆∞u Tr·ªØ
                    - **SAVE_ANALYSIS_FRAMES**: true/false (m·∫∑c ƒë·ªãnh: false)
                    - **SAVE_FORMAT**: images/gif/video/all (m·∫∑c ƒë·ªãnh: images)
                    - **MAX_FRAMES**: S·ªë frame t·ªëi ƒëa g·ª≠i AI (m·∫∑c ƒë·ªãnh: 5)
                    """
                    )

                with gr.Column():
                    current_config = f"""
### üìä C·∫•u H√¨nh Hi·ªán T·∫°i
- **Telegram**: {'‚úÖ B·∫≠t' if USE_TELE_ALERT else '‚ùå T·∫Øt'}
- **L∆∞u Frames**: {'‚úÖ B·∫≠t' if SAVE_ANALYSIS_FRAMES else '‚ùå T·∫Øt'}
- **ƒê·ªãnh D·∫°ng**: {SAVE_FORMAT.upper()}
- **Max Frames**: {os.environ.get('MAX_FRAMES', 5)}
                    """
                    gr.Markdown(current_config)

        # Event handlers
        def start_system(camera_idx):
            message, status = fall_system.start_detection(int(camera_idx))
            return message, status

        def stop_system():
            message, status = fall_system.stop_detection()
            return message, status

        def clear_alert_history():
            fall_system.alert_history.clear()
            fall_system.add_log("üóëÔ∏è ƒê√£ x√≥a l·ªãch s·ª≠ c·∫£nh b√°o", "info")
            return "‚úÖ ƒê√£ x√≥a l·ªãch s·ª≠ c·∫£nh b√°o!", fall_system.get_alert_history_display()

        def export_alert_report():
            if not fall_system.alert_history:
                return "‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ xu·∫•t!"

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"alert_report_{timestamp}.json"

            try:
                with open(filename, "w", encoding="utf-8") as f:
                    json.dump(fall_system.alert_history, f, ensure_ascii=False, indent=2)
                return f"‚úÖ ƒê√£ xu·∫•t b√°o c√°o: {filename}"
            except Exception as e:
                return f"‚ùå L·ªói xu·∫•t b√°o c√°o: {e}"

        # Bind events
        start_btn.click(start_system, inputs=[camera_index], outputs=[control_output, status_display])

        stop_btn.click(stop_system, outputs=[control_output, status_display])

        refresh_logs_btn.click(lambda: fall_system.get_logs_display(), outputs=[logs_display])

        refresh_alerts_btn.click(lambda: fall_system.get_alert_history_display(), outputs=[alert_display])

        clear_alerts_btn.click(clear_alert_history, outputs=[control_output, alert_display])

        export_alerts_btn.click(export_alert_report, outputs=[control_output])

        # Video upload event handlers
        def process_video(video_file):
            if not video_file:
                return "‚ùå Ch∆∞a ch·ªçn video!", "Vui l√≤ng ch·ªçn file video"

            # Process video in a separate thread to avoid blocking UI
            def video_worker():
                return fall_system.process_uploaded_video(video_file)

            return video_worker()

        def refresh_evidence():
            display_text, gif_paths = fall_system.get_evidence_gifs_display()
            return display_text, gif_paths

        def clear_evidence():
            try:
                # Clear from memory
                fall_system.evidence_gifs.clear()

                # Optionally delete files (uncomment if needed)
                # import glob
                # gif_files = glob.glob("evidence_gifs/*.gif")
                # for gif_file in gif_files:
                #     os.remove(gif_file)

                fall_system.add_log("üóëÔ∏è ƒê√£ x√≥a danh s√°ch b·∫±ng ch·ª©ng GIF", "info")
                display_text, gif_paths = fall_system.get_evidence_gifs_display()
                return "‚úÖ ƒê√£ x√≥a danh s√°ch b·∫±ng ch·ª©ng!", display_text, gif_paths
            except Exception as e:
                return f"‚ùå L·ªói x√≥a b·∫±ng ch·ª©ng: {e}", "L·ªói", []

        # Bind new events
        upload_btn.click(process_video, inputs=[video_upload], outputs=[upload_status, upload_info])

        refresh_evidence_btn.click(refresh_evidence, outputs=[evidence_list, evidence_gallery])

        clear_evidence_btn.click(clear_evidence, outputs=[upload_status, evidence_list, evidence_gallery])

        # Fast refresh for camera feed (0.1s for real-time video)
        def update_camera():
            return fall_system.get_current_frame()

        # Slower refresh for status/logs/alerts/evidence (2s for text data)
        def update_status_and_logs():
            if fall_system.is_running:
                evidence_text, evidence_gifs = fall_system.get_evidence_gifs_display()
                return (fall_system.get_status_info(), fall_system.get_logs_display(), fall_system.get_alert_history_display(), evidence_text, evidence_gifs)
            else:
                evidence_text, evidence_gifs = fall_system.get_evidence_gifs_display()
                return (fall_system.get_status_info(), gr.update(), gr.update(), evidence_text, evidence_gifs)

        # Set up dual auto-refresh timers using gr.Timer (Gradio 5.x)
        try:
            # Fast timer for camera feed (0.1s = 10 FPS)
            camera_timer = gr.Timer(0.1)
            camera_timer.tick(update_camera, outputs=[camera_feed])

            # Slower timer for status and logs (2s)
            status_timer = gr.Timer(2.0)
            status_timer.tick(update_status_and_logs, outputs=[status_display, logs_display, alert_display, evidence_list, evidence_gallery])

            print("‚úÖ Dual refresh timers set up: Camera 0.1s, Status/Logs 2s")

        except Exception as e:
            print(f"‚ö†Ô∏è Auto-refresh timers not available: {e}")
            # Fallback: single timer for everything at 1s
            try:
                fallback_timer = gr.Timer(1.0)

                def update_all():
                    if fall_system.is_running:
                        evidence_text, evidence_gifs = fall_system.get_evidence_gifs_display()
                        return (
                            fall_system.get_current_frame(),
                            fall_system.get_status_info(),
                            fall_system.get_logs_display(),
                            fall_system.get_alert_history_display(),
                            evidence_text,
                            evidence_gifs,
                        )
                    else:
                        evidence_text, evidence_gifs = fall_system.get_evidence_gifs_display()
                        return (fall_system.get_current_frame(), fall_system.get_status_info(), gr.update(), gr.update(), evidence_text, evidence_gifs)

                fallback_timer.tick(update_all, outputs=[camera_feed, status_display, logs_display, alert_display, evidence_list, evidence_gallery])
                print("‚ö†Ô∏è Using fallback timer: All components 1s")
            except:
                print("‚ùå No auto-refresh available - manual refresh only")

    return demo


if __name__ == "__main__":
    # Create and launch the interface
    demo = create_interface()

    print("üöÄ ƒêang kh·ªüi ƒë·ªông Gradio Web UI...")
    print("üì± Truy c·∫≠p giao di·ªán web t·∫°i: http://localhost:7860")
    print("üõë Nh·∫•n Ctrl+C ƒë·ªÉ d·ª´ng server")

    try:
        demo.launch(server_name="127.0.0.1", server_port=7860, share=False, show_error=True, quiet=False, prevent_thread_lock=False)  # Use localhost first
    except Exception as e:
        print(f"‚ùå Localhost launch failed: {e}")
        print("üîÑ Trying with network access...")
        try:
            demo.launch(server_name="0.0.0.0", server_port=7860, share=False, show_error=True, quiet=False, prevent_thread_lock=False)  # Allow external access
        except Exception as e2:
            print(f"‚ùå Network launch failed: {e2}")
            print("üåê Creating shareable link...")
            demo.launch(share=True, show_error=True, quiet=False, prevent_thread_lock=False)  # Create public link as last resort
